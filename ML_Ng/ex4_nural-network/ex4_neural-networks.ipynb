{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will implement the backpropagation algorithm for neural networks and apply it to the task of hand-written digit recognition. \n",
    "## Neural Networks\n",
    "- **Visualizing the data**\n",
    "- **Model representation**\n",
    "- **Feedforward and cost function**\n",
    "- **Regularized cost function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.optimize as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000,)\n",
      "(5000, 401) (25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "# Neural network model\n",
    "data = sio.loadmat(\"ex4data1.mat\")\n",
    "weights = sio.loadmat(\"ex4weights.mat\")\n",
    "x = data['X']\n",
    "y = data['y'].reshape(5000,)\n",
    "Theta1 = weights['Theta1']        # weights or parameters of layer1\n",
    "Theta2 = weights['Theta2']        # weights or parameters of layer2\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "X = np.hstack((np.ones((5000, 1)), x))  # layer1(input layer) has 400 + 1 units\n",
    "#Theta1 = np.zeros((25, 401))\n",
    "#Theta2 = np.zeros((10, 26))\n",
    "print(X.shape, Theta1.shape, Theta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28762916516131887\n"
     ]
    }
   ],
   "source": [
    "# Feedforward and cost function\n",
    "m = X.shape[0]\n",
    "K = 10                #total number of possible labels.\n",
    "\n",
    "Y = np.zeros((m, K))\n",
    "for i in range(m):    #recode the labels as vertors containing only values 0 or 1\n",
    "    if y[i] == 10:\n",
    "        Y[i, 0] = 1\n",
    "    else:\n",
    "        Y[i, y[i]] = 1\n",
    "#print(Y.shape)\n",
    "\n",
    "z2 = np.dot(X, Theta1.T)\n",
    "a2 = sigmoid(z2)           \n",
    "a2 = np.hstack((np.ones((a2.shape[0],1)), a2))   # layer2(hidden layer) has 25 + 1 units\n",
    "z3 = np.dot(a2, Theta2.T)\n",
    "a3 = sigmoid(z3)            # layer3(output layer) has K units\n",
    "h = np.vstack((a3[500:, :], a3[:500, :]))   # 这里这样处理的原因是因为matlab和python索引规则不同，具体原因见ex3。\n",
    "\n",
    "costJ = (1/m) * np.sum(-Y * np.log(h) - (1-Y) * np.log(1-h))\n",
    "print(costJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2876291651613191\n"
     ]
    }
   ],
   "source": [
    "# 法二\n",
    "J = 0\n",
    "for i in range(m):\n",
    "    tmp = 0\n",
    "    for k in range(K):\n",
    "        tmp = tmp + (-Y[i,k]*np.log(h[i,k]) - (1-Y[i,k])*np.log(1-h[i,k]))\n",
    "    J = J+tmp\n",
    "J = J/5000\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3837698590909236\n"
     ]
    }
   ],
   "source": [
    "# Regularized cost function\n",
    "lam = 1\n",
    "regJ = costJ + (lam/(2*m))*(np.sum(Theta1[:, 1:]**2) + np.sum(Theta2[:, 1:]**2))  # 注意：theta的第一列不要正则化\n",
    "print(regJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation\n",
    "- **Sigmoid gradient**\n",
    "- **Random initialization**\n",
    "- **Back propagation gradient**\n",
    "- **Gradient checking**\n",
    "- **Regularized Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid gradient function\n",
    "def sigmoidGradient(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization\n",
    "def randInitializeWeights(L_in, L_out):\n",
    "    epsilon_init = 0.12\n",
    "    #W = np.random.uniform(0, 1, (L_out, L_in)) * 2*epsilon_init - epsilon_init\n",
    "    W = np.random.rand(L_out, L_in + 1) * 2*epsilon_init - epsilon_init\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10) (5000, 25) (10, 26) (25, 401)\n"
     ]
    }
   ],
   "source": [
    "# Backpropagation gradient\n",
    "delta3 = h - Y\n",
    "delta2 = np.dot(delta3, Theta2) * np.hstack((np.ones((m, 1)), sigmoidGradient(z2)))\n",
    "delta2 = delta2[:, 1:]\n",
    "\n",
    "theta2_grad = np.dot(delta3.T, a2) / m\n",
    "theta2_grad[:, 1:] = theta2_grad[:, 1:] + (lam/m)*Theta2[:, 1:]   #Regularized Neural Networks\n",
    "theta1_grad = np.dot(delta2.T, X) / m\n",
    "theta1_grad[:, 1:] = theta1_grad[:, 1:] + (lam/m)*Theta1[:, 1:]   #Regularized Neural Networks\n",
    "print(delta3.shape, delta2.shape, theta2_grad.shape, theta1_grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unrolling parameters\n",
    "def unrollingParams(Theta1, Theta2):\n",
    "    unrolling_theta = np.append(Theta1.flatten(), Theta2.flatten())\n",
    "    return unrolling_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient checking\n",
    "#def computeNumericalGradient():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
